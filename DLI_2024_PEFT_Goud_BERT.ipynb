{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9jkLKRaGSal"
      },
      "source": [
        "# Efficiently Fine-Tune Seq2Seq Models with Low Rank Adaptation (LoRA)\n",
        "\n",
        "We are going to leverage Hugging Face [Transformers](https://huggingface.co/docs/transformers/index), [Accelerate](https://huggingface.co/docs/accelerate/index), and [PEFT](https://github.com/huggingface/peft). \n",
        "\n",
        "You will learn how to:\n",
        "\n",
        "1. Setup Development Environment\n",
        "2. Load and prepare the dataset\n",
        "3. Fine-Tune Multilingual BERT with LoRA and bnb int-8\n",
        "4. Evaluate & run Inference\n",
        "5. Cost performance comparison\n",
        "\n",
        "### Quick intro: PEFT or Parameter Efficient Fine-tuning\n",
        "\n",
        "[PEFT](https://github.com/huggingface/peft), or Parameter Efficient Fine-tuning, is a new open-source library from Hugging Face to enable efficient adaptation of pre-trained language models (PLMs) to various downstream applications without fine-tuning all the model's parameters. PEFT currently includes techniques for:\n",
        "\n",
        "- LoRA:Â [LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2106.09685.pdf)\n",
        "- Prefix Tuning:Â [P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](https://arxiv.org/pdf/2110.07602.pdf)\n",
        "- P-Tuning:Â [GPT Understands, Too](https://arxiv.org/pdf/2103.10385.pdf)\n",
        "- Prompt Tuning:Â [The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf)\n",
        "\n",
        "*Note: This tutorial was created and run on a NC24 VM on Azure, including 1 NVIDIA A100*\n",
        "### Plan:\n",
        "\n",
        "* Give overview on building blocks\n",
        " * Abstractive summarization\n",
        " * Evaluation metric (ROUGE)\n",
        " * BERT (https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)\n",
        " * The other LLM, which is yet to be decided (LLM2)\n",
        " * Prompt engineering\n",
        "* Practical steps: [Starting with preparing this section first]\n",
        "  * Install required libraries\n",
        "  *   Load and explore the dataset\n",
        "  *  SECTION 1: Abstractive summarization using BERT\n",
        "    * build summarization flow using BERT\n",
        "    * Train\n",
        "    * Evaluate\n",
        "  *  SECTION 2: Abstractive summarization using LLM2\n",
        "    * consruct summarization prompt(s)\n",
        "    * Generate summaries\n",
        "    * Evaluate\n",
        "\n",
        "### TODOs\n",
        "\n",
        "1. Test on colab T4\n",
        "2. List compute requirements\n",
        "3. Add requirements.txt and/or conda yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJmyBTEV-Ap6"
      },
      "source": [
        "# Install required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-a5N-RvHzEb",
        "outputId": "cbebe760-904e-44c8-88b8-60cf6cd3c6d9"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install arabert\n",
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCWpC2CAsSfU",
        "outputId": "63b7cbec-b5aa-4813-fadb-274c82a1ef7b"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCEWwDaAIzlj",
        "outputId": "78e7b167-4c8a-4cb5-ac7b-9c364d20c16c"
      },
      "outputs": [],
      "source": [
        "#install evaluation metric\n",
        "# !pip install rouge_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9iVGGjnGO2A"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOYfNBS-CKpy",
        "outputId": "e9b25fad-dc67-4186-e4b2-40ce915b85ea"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('Goud/Goud-sum')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2FL3f7sE_XC",
        "outputId": "6f92e8ab-bc0e-463f-c3cc-8426cb6e6393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'article': 'Ù…Ù†ÙŠØ± Ø§Ù„Ø¹Ù„Ù…ÙŠ Ù…Ù† Ù…Ø±Ø§ÙƒØ´: ØªØ­ÙˆÙ„ ÙØ¶Ø§Ø¡ Ù…Ù‚Ø± Ø§Ù„ØºØ±ÙØ© Ø§Ù„ÙÙ„Ø§Ø­ÙŠØ© Ø¨Ù…Ø¯ÙŠÙ†Ø© Ù…Ø±Ø§ÙƒØ´ØŒ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªØ¶Ù† ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø§Ù”Ø«Ù†Ø§Ø¡ØŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙŠÙ”ÙŠØ³ ÙˆØ§Ù”Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ¨ Ø§Ù„Ù…Ø³ÙŠØ± Ù„Ù„ØºØ±ÙØ© Ø§Ù„ÙÙ„Ø§Ø­ÙŠØ© Ø¨Ø¬Ù‡Ø© Ù…Ø±Ø§ÙƒØ´ Ø§Ù“Ø³ÙÙŠØŒ Ø§Ù•Ù„Ù‰ Ø­Ù„Ø¨Ø© Ù„Ù„Ø§Ø´ØªØ¨Ø§ÙƒØ§Øª ÙˆØ§Ù„Ù…Ù„Ø§Ø³Ù†Ø§ØªØŒ Ø¨Ø¹Ø¯ Ø§Ø´ØªØ¯Ø§Ø¯ Ø§Ù„Ø®Ù„Ø§Ù Ø¨ÙŠÙ† Ø§Ù„Ø¨Ø±Ù„Ù…Ø§Ù†ÙŠÙŠÙ† Ø­Ù…ÙŠØ¯ Ø§Ù„Ø¹ÙƒØ±ÙˆØ¯ ÙˆØ¹Ù…Ø± Ø®ÙÙŠÙØŒ Ø§Ù„Ù„Ø°ÙŠÙ† ÙŠÙ†ØªÙ…ÙŠØ§Ù† Ø§Ù•Ù„Ù‰ Ø­Ø²Ø¨ Ø§Ù„ØªØ¬Ù…Ø¹ Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø§Ù”Ø­Ø±Ø§Ø±ØŒ Ù…Ø§ ÙƒØ§Ø¯ ÙŠØ¹ØµÙ Ø¨Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ Ø¨Ø¹Ø¯ Ø§Ù†Ø·Ù„Ø§Ù‚ Ø´Ø±Ø§Ø±Ø© Ø§Ù„Ø§Ø´ØªØ¨Ø§Ùƒ Ø¨Ø§Ù„Ø§Ù”ÙŠØ§Ø¯ÙŠ Ø§Ù„ØªÙŠ Ø§Ù”Ø¬Ù‡Ø¶Øª ÙÙŠ Ù…Ù‡Ø¯Ù‡Ø§ Ø¨ØªØ¯Ø®Ù„ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø§Ø¶Ø±ÙŠÙ†. ÙˆØ­Ø³Ø¨ Ø´Ù‡ÙˆØ¯ Ø¹ÙŠØ§Ù†ØŒ ÙØ§Ù•Ù† Ø¹Ù…Ø± Ø®ÙÙŠÙØŒ Ø§Ù„Ø°ÙŠ ÙŠØ´ØºÙ„ Ø±ÙŠÙ”ÙŠØ³ Ø¬Ù…Ø§Ø¹Ø© Ø§Ù”ÙƒÙØ§ÙŠØŒ ÙˆÙ…Ø¯Ø¹Ù… Ø§Ù„Ø­Ø¨ÙŠØ¨ Ø¨Ù† Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ù…Ù†Ø³Ù‚ Ø§Ù„Ø§Ù‚Ù„ÙŠÙ…ÙŠ Ù„Ø­Ø²Ø¨ Ø§Ù„Ø§Ù”ØµØ§Ù„Ø© ÙˆØ§Ù„Ù…Ø¹Ø§ØµØ± Ø§Ù„Ø°ÙŠ ÙŠØªØ¬Ù‡ Ù„ØªÙˆÙ„ÙŠ Ø±ÙŠÙ”Ø§Ø³Ø© Ø§Ù„ØºØ±ÙØ© Ù„ÙˆÙ„Ø§ÙŠØ© ØªØ§Ù†ÙŠØ©ØŒ Ø±ÙØ¶ Ø¯Ø®ÙˆÙ„ Ø­Ù…ÙŠØ¯ Ø§Ù„Ø¹ÙƒØ±ÙˆØ¯ Ù„Ù„Ù…Ù†Ø§ÙØ³Ø© Ø¹Ù„Ù‰ Ø±ÙŠÙ”Ø§Ø³Ø© Ø§Ù„ØºØ±ÙØ©ØŒ ÙˆØ§ØµÙØ§ Ø§Ù•ÙŠØ§Ù‡ Ø¨Ù€ â€œØ§Ù„Ø§Ù”Ù…ÙŠ Ø§Ù„Ø°ÙŠ Ù„Ø§ÙŠÙÙ‚Ù‡ Ø´ÙŠÙŠÙ”Ø§â€ØŒ Ù„ÙŠØ¯Ø®Ù„ Ø§Ù„Ø·Ø±ÙØ§Ù† ÙÙŠ Ù…Ù„Ø§Ø³Ù†Ø§Øª ÙƒÙ„Ø§Ù…ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù”Ù† ÙŠØªØ­ÙˆÙ„ Ø§Ù„ØµØ±Ø§Ø¹ Ø§Ù•Ù„Ù‰ ØªØ´Ø§Ø¨Ùƒ Ø¨Ø§Ù„Ø§Ù”ÙŠØ¯ÙŠ. ', 'headline': 'Ø¨Ø±Ù„Ù…Ø§Ù†ÙŠÙŠÙ† Ù…Ù† Ø­Ø²Ø¨ Ø§Ù„Ø­Ù…Ø§Ù…Ø© Ù‚Ù„Ø¨ÙˆÙ‡Ø§ Ø¨ÙˆÙ†ÙŠØ§ Ù‚Ø¨Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø±Ø¦ÙŠØ³ ÙˆØ£Ø¹Ø¶Ø§Ø¡ ØºØ±ÙØ© Ø§Ù„ÙÙ„Ø§Ø­Ø© Ø¨Ø¬Ù‡Ø© Ù…Ø±Ø§ÙƒØ´ Ø¢Ø³ÙÙŠ (ØµÙˆØ±)', 'categories': \"['Ø¢Ø´ ÙˆØ§Ù‚Ø¹', 'Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©']\"}\n"
          ]
        }
      ],
      "source": [
        "#Data Exploration\n",
        "print(dataset['train'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWLeQq7OyXvX",
        "outputId": "a3c413ed-1ccb-4a98-8357-c361578b9458"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'headline', 'categories'],\n",
              "        num_rows: 139288\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'headline', 'categories'],\n",
              "        num_rows: 9497\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'headline', 'categories'],\n",
              "        num_rows: 9497\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 139288\n",
            "Test dataset size: 9497\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
        "print(f\"Test dataset size: {len(dataset['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ø¨Ø±Ù„Ù…Ø§Ù†ÙŠÙŠÙ† Ù…Ù† Ø­Ø²Ø¨ Ø§Ù„Ø­Ù…Ø§Ù…Ø© Ù‚Ù„Ø¨ÙˆÙ‡Ø§ Ø¨ÙˆÙ†ÙŠØ§ Ù‚Ø¨Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø±Ø¦ÙŠØ³ ÙˆØ£Ø¹Ø¶Ø§Ø¡ ØºØ±ÙØ© Ø§Ù„ÙÙ„Ø§Ø­Ø© Ø¨Ø¬Ù‡Ø© Ù…Ø±Ø§ÙƒØ´ Ø¢Ø³ÙÙŠ (ØµÙˆØ±)'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sample record\n",
        "print(dataset['train'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO6qs280Fafk"
      },
      "source": [
        "Preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw1DtI0777FF"
      },
      "source": [
        "#Abstractive summarization using BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVnp5gfY8Die"
      },
      "source": [
        "Pick the evaluation metric and explain what it means, here I'm going with rouge\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ksKipQfcIOlk"
      },
      "outputs": [],
      "source": [
        "#Evaluating model performance\n",
        "#Defining Metrics:\n",
        "\n",
        "#Explain the evaluation metrics you will use (e.g., ROUGE, BLEU).\n",
        "from datasets import load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Go9b-QOZ6b6P"
      },
      "outputs": [],
      "source": [
        "#from transformers import BertTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "#from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "#model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "#preprocessor = ArabertPreprocessor(model_name=\"\")\n",
        "#tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VNYjdrvvc9Q"
      },
      "source": [
        "## build summarization flow using BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKiXlAm_Tlkw",
        "outputId": "66c18378-51fb-4ce3-f590-0eb27ff94e84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
            "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, Dataset, load_metric\n",
        "from transformers import BertTokenizer, EncoderDecoderModel, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name)\n",
        "\n",
        "# Set decoder_start_token_id\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8320199d383145e382058c1f6edee467",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/148785 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max source length: 512\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "895cd8a7287c4f968e40e06cd8331d1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/148785 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max target length: 16\n"
          ]
        }
      ],
      "source": [
        "from datasets import concatenate_datasets\n",
        "import numpy as np\n",
        "# The maximum total input sequence length after tokenization. \n",
        "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
        "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"article\"], truncation=True), batched=True, remove_columns=[\"article\", \"categories\"])\n",
        "input_lenghts = [len(x) for x in tokenized_inputs[\"input_ids\"]]\n",
        "# take 85 percentile of max length for better utilization\n",
        "max_source_length = int(np.percentile(input_lenghts, 85))\n",
        "print(f\"Max source length: {max_source_length}\")\n",
        "\n",
        "# The maximum total sequence length for target text after tokenization. \n",
        "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
        "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"categories\"], truncation=True), batched=True, remove_columns=[\"article\", \"categories\"])\n",
        "target_lenghts = [len(x) for x in tokenized_targets[\"input_ids\"]]\n",
        "# take 90 percentile of max length for better utilization\n",
        "max_target_length = int(np.percentile(target_lenghts, 90))\n",
        "print(f\"Max target length: {max_target_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cbm0VjhYkmgL"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizer(examples[\"article\"], max_length=512, truncation=True, padding=\"max_length\")\n",
        "    outputs = tokenizer(examples[\"headline\"], max_length=150, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    inputs[\"decoder_input_ids\"] = outputs[\"input_ids\"]\n",
        "    inputs[\"labels\"] = outputs[\"input_ids\"].copy()\n",
        "\n",
        "    # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
        "    inputs[\"labels\"] = [[(label if label != tokenizer.pad_token_id else -100) for label in labels] for labels in inputs[\"labels\"]]\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c99a7211424a4d858507351a13d68efd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/139288 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4b8ca5d233540768c29d1b755cfe6da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9497 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed4918c5701e4c48a31a03348553ad51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9497 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys of tokenized dataset: ['input_ids', 'token_type_ids', 'attention_mask', 'decoder_input_ids', 'labels']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "daf8b3596b8041f6a1d0a590e61a119f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/2 shards):   0%|          | 0/139288 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61068863224d4140a3913f175a552d78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/9497 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"article\", \"categories\", \"headline\"])\n",
        "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
        "# save datasets to disk for later easy loading\n",
        "tokenized_dataset[\"train\"].save_to_disk(\"data/train\")\n",
        "tokenized_dataset[\"test\"].save_to_disk(\"data/eval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZmWFtotgFNj",
        "outputId": "e0cdedc2-b65f-4d4d-afa2-227a938d8763"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alizaidi/micromamba/envs/peft/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "\n",
        "# Define data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    save_total_limit=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,769,472 || all params: 385,964,283 || trainable%: 0.4585\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
        "\n",
        "# Define LoRA Config \n",
        "lora_config = LoraConfig(\n",
        " r=16, \n",
        " lora_alpha=32,\n",
        " target_modules=[\"query\", \"value\"],\n",
        " lora_dropout=0.05,\n",
        " bias=\"none\",\n",
        " task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "# prepare int-8 model for training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# add LoRA adaptor\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# trainable params: 18874368 || all params: 11154206720 || trainable%: 0.16921300163961817"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxfjxJ76gLMW",
        "outputId": "e378b26f-3c3b-4b50-fae2-d52e3c55f112"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2722794/1378865303.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge = load_metric(\"rouge\")\n"
          ]
        }
      ],
      "source": [
        "# Define ROUGE metric\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    labels = [[(label if label != -100 else tokenizer.pad_token_id) for label in labels] for labels in labels]\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract the ROUGE scores\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p4FSmkk-uVEP"
      },
      "outputs": [],
      "source": [
        "# Sample a subset of the tokenized training data\n",
        "subset_fraction = 0.05  # 5% of the training data\n",
        "train_subset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(int(subset_fraction * len(tokenized_datasets[\"train\"]))))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "output_dir=\"goud-bert\"\n",
        "\n",
        "# Define training args\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\t\tauto_find_batch_size=True,\n",
        "    learning_rate=1e-3, # higher learning rate\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=f\"{output_dir}/logs\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=500,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnge3142vi5M"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "UvfNpDHbhVwu",
        "outputId": "c039c6c4-aa95-4566-c90a-5831d63156c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "/home/alizaidi/micromamba/envs/peft/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='136' max='52233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  136/52233 00:30 < 3:17:20, 4.40 it/s, Epoch 0.01/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ-M9_oBvnxV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4c9K1rwkGfv"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAeFInMJsyH_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./fine_tuned_bert2bert_model\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_bert2bert_model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
